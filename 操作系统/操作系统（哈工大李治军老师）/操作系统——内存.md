

# 操作系统——内存



> ​	计算机把一段程序放到内存当中，CPU不断地取值执行取值执行，计算机工作起来，都是在使用内存的过程



### 内存使用与分段

内存使用：将程序放到内存中，PC指向开始地址

编译完，可执行文件放磁盘上

重定位：修改程序中的地址（相对地址）（在编译时、载入时）

编译时重定位的程序只能放在内存固定位置

载入时重定位的程序一旦载入内存就不能动了（载入时根据内存灵活修改，额外耗时）

重定位最合适的时机——运行时重定位（每执行一条指定都要从逻辑地址算出物理地址：地址翻译）

基地址（base）-> 存PCB里面，进行上下文切换，从磁盘切内存可能都涉及base基地址的修改（寄存器上）

> 执行指令时第一步先从PCB中取出这个基地址



#### 分段

由若干个部分（段）组成

> 符合用户观点：用户可独立考虑每个段（分治）

> 怎么定位具体指令（数据）：<段号，段内偏移>

> 如mov [es:bx], ax



不是将整个程序，是将各段分别放入内存

比如例子：

> ​	堆、栈区，可扩展可扩大区，在程序运行过程中，在堆栈区占用空间大于分配空间，且剩余空余空间不足以使用的时候。进程会重新分配区域，而这个如果是将程序全部放入内存当中，这个时候就会涉及到程序全部的copy操作，意味着这段时间程序操作无法执行。而如果采用分段后者的话，只涉及到堆栈区的重分配。

不同段的重定位基址不一样。

mov [DS:100]，%eax	jmpi 100，CS

GDT表长得像段表（OS的）

LDT表

| 段号 | 基址 | 长度 | 保护 |
| ---- | ---- | ---- | ---- |
| 0    | 180K | 150K | R    |
| 1    | 360K | 60K  | R/W  |
| 2    | 70K  | 110K | R/W  |
| 3    | 460K | 40K  | R    |



真正的故事：GDT+LDT





### 内存分区与分页



每个PCB 中都有一个LDT表用于重定位，存放于寄存器当中

进程当中切换（上下换切换），PCB转换，LDT表切换，LDTr更换指向另外一张LDT表中

确保在自己的进程空间中进行跳转，实现互不影响



- 第一部分段
- 第二部分找一段空闲分区（划分*）
- 第三部分做好重定位映射关系，LDT表



如何在内存当中找到空闲分区？（内存怎么割）

> ​	怎样可以将程序的各个段载入到相应的内存分区当中



固定分区和可变分区



固定分区

- 等分
- 操作系统初始化时将内存等分成k个分区



可变分区

可变分区的管理过程——核心数据结构

可变分区的管理——请求分配

 

已分配分区表

| 始址 | 长度 | 标志 |
| ---- | ---- | ---- |
| 0K   | 100K | OS   |
| 100K | 100K | Seg1 |
| 200K | 50K  | Seg2 |



空闲分区表

| 始址 | 长度 |
| ---- | ---- |
| 250K | 250K |



> 如果段1不再需要，已分配分区表与空闲分区表

| 始址 | 长度 | 标志 |
| ---- | ---- | ---- |
| 0K   | 100K | OS   |
| 200K | 50K  | Seg2 |

| 始址 | 长度 |
| ---- | ---- |
| 250K | 250K |
| 100K | 100K |





> ​	操作系统没有对错的算法，只有优缺点不同的算法



可变分区的管理——再次申请

一个段提出内存请求：reqSize = 40K

> 怎么办？

- 在2个空闲分区

| 始址 | 长度 |
| ---- | ---- |
| 350K | 150K |
| 200K | 50K  |

- 首/最先适配：（350，150）
- 最佳适配：（200，50）
- 最差适配：（350，150）

不同算法不一样

最佳适配O(n)

首先适配O(1)



1.维护空闲分区表

2.内存分区管理算法

3.LDT的修改



目的：让段更好的放入内存



#### 分页

> ​	引入分页：解决内存分区导致的内存效率问题



可变分区造成的问题：内存碎片（它的解决方法：将空闲分区合并，需要移动一个段（复制内容）：内存紧缩。造成这个段死机状态，不合理）

- 内存紧缩需要花费大量时间，如果复制速度1M/S秒，则1G内存的紧缩时间为1000S≈17mins

不可行



解决方法：

从连续到离散

> ​	让给的面包没有谁都不想要的粉末

- 将面包切成片，将内存分成页
- 针对每个段内存请求，系统一页一页的分配给这个段



每一页单位为4K

问题：此时需要内存紧缩吗？最大内存浪费是多少？

一个段最多浪费一页，不需要内存紧缩，时间耗费太大。



物理内存的角度希望采用分页的特点、用户希望分段的特点



页已经载入了内存，接下来的事情...

<img src="C:\Users\10505\AppData\Roaming\Typora\typora-user-images\image-20211009170407084.png" alt="image-20211009170407084" style="zoom:50%;" />

- 页0放在页框5中，页0中的地址就需要重定位

页中的仍然是逻辑地址

| Path#  | Offset       |
| ------ | ------------ |
| 第几页 | 页面尺寸(4K) |

mov[0x2240], %eax

右移12位，/4K

逻辑地址 0x02	0x240

MMU（内存管理单元）

页表项

| 页号 | 页框号 | 保护 |
| ---- | ------ | ---- |
| 0    | 5      | R    |
| 1    | 1      | R/W  |
| 2    | 3      | R/W  |
| 3    | 6      | R    |

<img src="C:\Users\10505\AppData\Roaming\Typora\typora-user-images\image-20211009170916055.png" alt="image-20211009170916055" style="zoom: 33%;" />



- move 汇编指令拿到
- 除于页面尺寸（4K），右移12位，获得逻辑地址与偏移量
- 逻辑地址对应PCB中的页表指针，获得对应的物理地址页框号，从而算出物理地址：0x3240

全程MMU自动算



### 多级页表与快表

为了提高内存空间利用率，页应该小，但是页小了页表就大了...



4G/4K = 1M

> ​	纸上和时机使用总是存在很大差别

- 页面尺寸通常为4K，而地址是32位的，有2^20个页面
- 2^20个页表项都得放在内存中，需要4M内存；
- 系统中并发10个进程，就需要40M 内存



实际上大部分逻辑地址根本不会用到

根据逻辑页找到物理页



**多级页表**

> ​	用书的章目录和节目录来类比思考

页目录表（章）+ 页表（节）

逻辑地址

| 10bits   | 10bits | 12bits |
| -------- | ------ | ------ |
| 页目录号 | 页号   | Offset |



即保证了连续存储，通过章节结构来节省页表内存，额外无谓浪费的页表项减少，内存碎片减少

<img src="C:\Users\10505\AppData\Roaming\Typora\typora-user-images\image-20211009234618627.png" alt="image-20211009234618627" style="zoom: 33%;" />

> ​	提高了空间效率，但是在时间上？

每多增加一级页表，就多增加一次访问内存

​	但是，多级页表的增加也导致访存次数的增多，每增加一级页表，访存次数就多一次，当操作系统为64位系统时，访存次数就会增加到5、6次，如何既能保证空间还能尽量降低时间呢？

- 多级页表增加了访存的次数，尤其是64位的系统

TLB 是一组相联快速存储，是寄存器



快表

使用快表来解决多级页表的多次访存次数。

​	对于一些经常用到的页表，我们可以将其放在TLB中，而TLB是寄存器，执行速度非常快，可以在硬件电路上做到一次达到。

​	当在TLB找不到时，就回到多级页表中去查找，也就是TLB和多级页表的合作

![在这里插入图片描述](https://img-blog.csdnimg.cn/2020051314315255.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2p1bXBfaW50b196ZWhl,size_16,color_FFFFFF,t_70)



​	两个机制，在此处保证了多级页表在内存中是连续的，提高空间利用率，而最近使用的页表项，放在快表中。

​	最终合在一起，最终保证实际上快，空间利用率高

>  充分体现操作系统折中的思想



TLB 得以发挥作用的原因（在时间上提升的效率）

- TLB 命中时效率会很高，未命中时效率降低

```
  有效访问时间 = HitR * (TLB+MA) + (1-HitR)*(TLB+2MA)
  HitR：命中率
  MA: 内存访问时间
  TLB: TLB时间
  在单级页表情况下
  有效访问时间=98%x(20ns + 100ns) + 2%x(20ns + 200ns) = 122ns
  有效访问时间=10%x(20ns + 100ns) + 90%x(20ns + 200ns) = 210ns
```

- 要想真正实现“近似访存1次”，TLB的命中率应该更高
- TLB越大越好，但TLB很贵，通常只有[64, 1024]

TLB的置换算法在后续内存置换涉及



> 为什么TLB条目数可以在64 - 1024之间

相比2^20个页，64很小，为什么TLB就能起作用？

- 程序的地址访问存在局部性
- 空间局部性（Locality in Space）

<img src="C:\Users\10505\AppData\Roaming\Typora\typora-user-images\image-20211010000645387.png" alt="image-20211010000645387" style="zoom:50%;" />





​	比如while、for、if-else经常会发现一段时间会经常访问这段逻辑页号



例子

> 最近期末考试，我第一天考试我天天在复习数学和语文，快表就经常访问数学和语文，第二天考英语地理，我天天复习英语地理，快表就经常访问英语地理



从空间上高效，时间上也快速的分页机制





### 段页结合的实际内存管理



> ​	段、页结合：程序员希望用段，物理内存系统用页，所以...



​	用户角度上来看，用户程序对应到虚拟内存当中。让用户感觉到有段的存在，而在操作系统将虚拟内存中所谓的段，映射到实际按页分配的物理内存当中。



​	段、页同时存在：段面向用户/页面向硬件



`虚拟内存`：我们让应用程序分为段，然后映射到一段虚拟内存中，再让虚拟内存映射到物理内存中的页中，这样就完成了段和页的结合



**段、页同时存在时的重定位(地址翻译)**

段号 + 偏移 cs:ip 

页号 + 偏移

- 根据段号找到偏移求出虚拟地址
- 根据虚拟地址求出页号找到物理地址



<img src="C:\Users\10505\AppData\Roaming\Typora\typora-user-images\image-20211010204839852.png" alt="image-20211010204839852" style="zoom:33%;" />



> 内存管理核心就是内存分配，所以从程序放入内存、使用内存开始...

- 分配段、建段表
- 分配页、建页表
- 从进程fork中的内存分配开始...



 	从虚拟内存中割出一个区域给数据段，而这个数据段被隔成几个页放在物理内存中的页.

<img src="https://img-blog.csdnimg.cn/20200513175255929.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2p1bXBfaW50b196ZWhl,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom: 67%;" />

使用内存分为五步

- 分配段
- 建段表
- 分配页
- 建页表
- 重定位



> 故事从fork()开始

- fock() -> sys_fork -> copy_process



- 分配虚拟内存、建段表

```c++
fork()->sys_fork->copy_process

//在linux/kernel/fork.c中
int copy_process(int nr, long ebp, ...)
{
    ...
    copy_mem(nr, p);
    ...
}
int copy_mem(int nr, task_struct *p) //nr表示第几个进程，p为PCB
{
    unsigned long new_data_base;
    new_data_base = nr*0x4000000; // 64M*nr ，这一步完成了虚拟内存的分割
    set_base(p->ldt[1], new_data_base);
    set_base(p->ldt[2], new_data_base);
    /*上面两句完成了段表的初始化，这里将64M的内存既用作代码段又用作数据段，因此基址是相同的*/
}
```

p是PCB

<img src="https://img-blog.csdnimg.cn/20200513175335872.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2p1bXBfaW50b196ZWhl,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom:50%;" />

在上面的程序中，每个进程占64M的虚拟地址空间，互不重叠，因此，他们可以共用一套页表，但是实际中页号是可能重叠的，因此需要有单独的页表



- 分配内存、建页表

```c
int copy_mem(int nr, task_struct *p)
{
    unsigned long old_data_base;
    old_data_base = get_base(current->ldt[2]);
    copy_page_tables(old_data_base, new_data_base, data_limit); 
    /*子进程与父进程共用一套页表，子进程不需要分配内存，因为父进程已经分配好了，子进程只需要跟父进程拷贝一份相同的页表，传递两个虚拟地址，重新建一个页表，页表内容和父进程相同*/
}
int copy_page_tables(unsigned long from, unsigned long to, long size)
{
    from_dir = (unsigned long *)((from>>20) & 0xffc);
    to_dir = (unsigned long *)((to>>20) & 0xffc);
    size = (unsigned long)(size+0x3fffff)>>22;
    for(; size-->0; from_dir++,to_dir++)
    {
        from_page_table=(0xfffff000&from_dir);
        to_page_table = get_free_page();
    }
}
```

我们解释一下`int copy_page_tables(...)`函数

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200513175411724.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2p1bXBfaW50b196ZWhl,size_16,color_FFFFFF,t_70)

```c
from_dir = (unsigned long *)((from>>20) & 0xffc);
```



`	from`是32位虚拟地址，我们将它右移22位就得到页目录号了，再乘于4，因为一个页目录大小为4个字节，因此相当于右移20位



`from_dir`就是一个指向页目录号的指针，接下来，就是根据这个指针找到每一个页号和对应的页框号

```c
for(; size-->0; from_dir++,to_dir++)
{
    to_page_table = get_free_page(); /
    *分配一个物理内存页来保存页表,就是在mem_map中找一段没有被用过的内存*/
    *to_dir = ((unsigned long)to_page_table) | 7;
}
```

接下来，就是将父进程的页表拷贝到子进程中

```c
// nr = 1024;
for(; nr-->0; from_page_table++; to_page_table++)
{
    this_page = *from_page_table;
    this_page &=~2; //只读，父进程子进程共享一个页
    *to_page_table = this_page;
    *from_page_table = this_page;
    this_page -= LOW_MEM;
    this_page >> = 12;
    mem_map[this_page]++;  //这一页被共享了，当其中一个释放，还有其他的在使用，因此要+1
}
```

​	这里如果你想给子进程单独设置一个页，只要调用`get_free_page()`得到一个空闲的内存地址，再将其赋给子进程的页表就可以了。



复制页表，公用物理页，写时复制

- 只有将程序放入内存中才可以运行



操作系统创建段表、页表

MMU 执行指令重定位



写时复制

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200513175455440.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2p1bXBfaW50b196ZWhl,size_16,color_FFFFFF,t_70)

写的时候，新申请物理页写入数据，重新映射页表



> ​	在上面的程序中，如果我们对父进程指向p=0x300, *p=7,那么父进程就会在通过重定位找到物理地址，然后将7写入，然后父进程fork()一个子进程，因为公用的是一套页表，并且将页表置位只读，因此子进程指向p=0x300, *p=8时，就会重新申请一段内存，修改页表，然后MMU重新计算，然后执行*p = 8,这样就实现了进程之间的分离。



### 内存换入——请求分页

Swap in

> 实现虚拟内存就应该有换入换出





用户眼里的内存

- 用户可随意使用该“内存”，就像单独拥有4G“内存“
- 这个”内存“怎么映射到物理内存，用户全然不知





用换入（从磁盘换进来）、换出实现“大内存”

我们设置虚拟内存大小位4G,但是实际内存只有1G，所以虚拟内存没办法完整的映射到实际内存中，那么如何才能让用户觉得虚拟内存就是实际的内存呢？换入换出可以实现这一点，当用户使用虚拟内存的(0G-1G)时，就将这一段的虚拟内存映射到物理内存上。

当用户使用(3G-4G)处的虚拟内存时，就将虚拟内存(3G-4G)映射到物理内存上，这样就相当于4G的虚拟内存都可以使用了



**虚拟内存：仓库**

**物理内存：门店**



请求的时候才映射！



**请求调页**（中断）-> 页错误处理程序

当MMU进行重定位时，发现虚拟内存没有映射，就会发起**中断**，同时不让PC+1,然后从磁盘中查找对应的页，**再从内存中申请一段内存**，**将磁盘中读到的页放入内存中，再建立映射，最后中断返回**，**MMU重新计算，然后重新执行中断时的那一条指令**。

 

**一个实际系统的请求调页**

```c
请求调页，当然从缺页中断开始
中断号      名称                说明
12      Segment not present    描述符所指的段不存在
14      Page fault             页不在内存
void trap_init(void)
{
    set_trap_gate(14, &page_fault);
}
#define set_trap_gate(n,addr) \
    _set_gate(&idt[n], 15, 0, addr);

//在linux/mm/page.s
.globl _page_fault
    xchgl %eax,(%esp)  //错误码esp被压入栈中
    ...
    movl $0x10, %edx
    ...
    movl %cr2, %edx //cr2寄存器里存放着页错误线性地址，将其赋给edx;
    pushl %edx
    pushl %eax
    ...
    call _do_no_page  //调用_do_no_page函数，参数就是eax、edx,保存在栈中
    ...
//在linux/mm/memory.c中
void do_no_page(unsigned long error_code, unsigned long address)
{
    address &= 0xfffff000  //将后面三位去掉，得到页面地址
    tmp = address-current->state_code;  //页面对应的偏移
    if(!current->executable || tmp>=current->end_data)
    {
        get_empty_page(address);
            return;
    }
    page = get_free_page();  //申请内存空间
    bread_page(page, current->executable->i_dev, nr);  //从磁盘中读缺少的页到page中
    put_page(page, address);  //建立页表映射
}
//在linux/mm/memory.c中
unsigned long put_page(unsigned long page, //物理内存
                        unsigned long address)
{
    unsigned long tmp, *page_table;
    page_table = (unsigned long *)((address>>20)&ffc);  //找到页目录项
    if((*page_table)&1)
        page_table = (unsigned long *)(0xfffff000&*page_table);
    else
    {
        tmp = get_free_page();
        *page_table = tmp|7;
        page_table = (unsigned long *)tmp;
    }
    //根据页目录项找到页表项
    page_table[(address>>12)&0x3ff] = page|7; //将页表项映射到新建的物理内存上
    return page;
}

```

- 申请空闲页
- 磁盘上把这一页读进来
- 建立页表映射



### 内存换出

虚拟内存的实现靠的是换入和换出，上面我们只是实现了换入，但是内存终究是有限的，必须从内存中取出一部分页来换出才能得到空闲的内存



```c
page = get_free_page();  //申请内存空间
bread_page(page, current->executable->i_dev, nr);  //从磁盘中读缺少的页到page中
```

- 并不能总是获得新的页，内存是有限的

  需要选择一页淘汰，换出到磁盘，选择哪一页？



- FIFO，最容易想到，但如果刚换入的页马上又要换出怎么办？
- 有没有最优的淘汰方法？MIN
- 最优淘汰方法能不能实现，是否需要近似？LRU



LRU 的准确实现，用时间戳（Redis的淘汰算法也是）

**使用时间戳**

**实现思路**：每一个页维护一个时间戳，当被使用时，修改时间戳，换页时选最小的时间戳换出

该思路是可以实现LRU，但是代价太大，每执行一条指令就需要在页中修改时间戳，并且还要处理时间戳溢出的情况，在实际中不可行



**页面栈**

**实现思路**：维护一个栈，当一个页被用到时，将其换到栈顶，每次页面换出就淘汰栈底的页

该思路可行，但是同样的代价较大，每一次执行指令需要修改几次指针。



#### LRU算法近似实现 --将时间计数变为是和否

**SCR(Second Chance Replacement)算法 | Clock Algorithm 算法**

- 每个页加一个引用位R(reference bit)
- 选择淘汰页：扫描R，是1时清0，并继续扫描；是0时淘汰该页

因为只是修改一位，因此这一项工作可以由MMU来完成，速度非常快。



**Clock算法的分析和改造**

如果缺页很少(程序具有局部性)，那所有的R都会变成1，这样这个算法就退化成FIFO算法了，因此需要定时清除R位，也就是定义一个**定时清除R位指针**，快慢指针来清除，该扫描指针要比**选择淘汰页**的扫描指针速度快，这就是这个算法叫做Clock算法的原因。



#### 进程页框分配

- 给进程分配多少页框(帧frame)

  - 分配的多，请求调页导致的内存高效利用就没有意义了，而且内存也是有限的

  - 分配的少

    ![Y03VT1.png](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9zMS5heDF4LmNvbS8yMDIwLzA1LzE0L1kwM1ZUMS5wbmc?x-oss-process=image/format,png)

    解释：系统内进程增多=> 每个进程的缺页率增大 => 缺页率增大到一定程度，进程总等待调页完成（不断在磁盘和内存中移动换入换出，CPU只能等着，DMA执行这个过程） => CPU 利用率降低 => 进程进一步增多，缺页率更大...

  - 颠簸现象



**因此，给进程分配的页框数量必须适中，不能太多也不能太少，还要限制进程的个数**

页框数量应该能覆盖一个局部（求工作集）

<img src="C:\Users\10505\AppData\Roaming\Typora\typora-user-images\image-20211012001443920.png" alt="image-20211012001443920" style="zoom:50%;" />



换入换出图

















