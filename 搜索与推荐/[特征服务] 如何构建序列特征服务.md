# 如何构建序列特征服务

转自：https://zhuanlan.zhihu.com/p/509245253

## 1. 什么是序列特征？

推荐系统中的序列特征，大体可以理解为用户的各种行为，比如常见的: 曝光+点击+收藏+转发+评论+关注等。

另一种跟序列比较相关的是session。比如用户可能在一个会话窗口进行浏览，每个session内的兴趣比较集中，行为序列可能比较相似，但跨session的兴趣就可能差异比较大。

那序列特征数据是从哪里来的呢？

客户端在前期规划开发时，会在各个页面中的关键按钮进行事件埋点，记录用户每次触发的行为信息并上报。比如常见的抖音页面，就有以下的行为:

![图片](https://mmbiz.qpic.cn/mmbiz_png/JwPJIDC9UgKxQj4OOLaleJZT6erXltuxpVqbicsJktJXtB1mhm8e9Q6J5ooMMqbgMYqEE9aLZMSRIKibsjaFQcoA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

这些不同的行为，可以用来做很多策略: 比如加投用户最近关注账号的相似账号，比如过滤用户最近举报或者不感兴趣的博主或者分类等等。

另一方面，行为列表也是排序模型中非常重要的一类特征，一般常见的做法是使用pooling，比如谷歌的[《Deep Neural Networks for YouTube Recommendations》[1]中针对行为序列做的avg pooling。

当然这几年针对序列特征有更多的模型以及方法，前人有非常不错的分享总结，这里不再赘述，感兴趣可以看看:

1. 谈谈推荐系统中的用户行为序列建模[2]
2. 深入理解推荐系统：十大序列化推荐算法梳理[3]

我们主要聊聊如何构建一个满足推荐要求的序列特征服务。

## 2. 工程考量与实践

这一章节主要介绍序列特征在生产环节可能碰到的一些工程上的问题和常见的解决方案，相对聚焦于模块之间的交互，技术组件的某些实现细节，会放在后面的系列文章进行总结分享。

### 2.1 实时性

实时性是序列特征非常重要的特性之一，实时性越强，越能反映用户当下的兴趣变化。

在推荐过程中，用户行为生产与使用的链路如下:

1. 客户端app侧埋点记录用户事件，并上报信息
2. 实时任务消费用户事件，进行etl后存储序列结果
3.  推荐链路使用序列特征进行排序或者重排
4. 在下一个请求中将topk个推荐内容返回给客户端。

步骤1到4的时间越短，实时性越高，推荐结果也就更灵敏。这里单指序列特征的实时性。实际上推荐系统背后是复杂的模型，数据从生产到作用于下一刷请求，更多的是背后的深度模型学习到行为对应的样本，并更新线上模型的权重。对于样本和模型的实时性，就不展开，细节放到后面的系列文章。

![图片](https://mmbiz.qpic.cn/mmbiz_png/JwPJIDC9UgKxQj4OOLaleJZT6erXltuxEsQNrYsN1ECIIx6dfj27ibMibia03vpO0gYMKOZg4CaKW6XGN223hCWeQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

上述步骤1-4中，影响序列特征实时性的主要是第1-2步。

理论上，用户有行为后当即上报，实时性最好。但考虑到客户端业务复杂，通常会有非常多的埋点数据。除了推荐相关的行为，可能还会有搜索，背景音乐以及一些电商操作行为(如上图的抖音app)，基本上一切可以触碰交互的地方都会进行数据埋点上报。

同时，除了上报行为，一般还会附带一些业务信息，比如播放进度，当前所处的页面，用户设备号，网络上下文等，埋点数据量很大，每个行为都实时上报的话，后端以及app都会有不小的压力。因此一般情况都是客户端会采取定时 + 定量的策略，每到达一定行为条数或者到达一个时间时，就会将内存中的行为批量上报。

正常情况下，行为的时间与上报的时间一般都是10秒以内的差距。(可以消费到数据时用当下时间减去行为时间)

另一个可能的延迟是步骤2中的队列消费&处理带来的。

首先是数据写入队列以及消费队列带来的延迟。这种数据接入MQ业界常用做法是使用kakfa或者基于kafka二次改造，比如腾讯的开源的TubeMQ[4](开源版本好像叫InLong)。

**kafka本身也会通过批量发送来提升性能，同时kafka有个水位机制，用来进行副本的数据同步，这也会带来一点点的消息延迟。**

![图片](https://mmbiz.qpic.cn/mmbiz_png/JwPJIDC9UgKxQj4OOLaleJZT6erXltuxdZcN9ibN3dogw0qhia7icUQmGRAibljiaeoWmFrH4NIDhkk5niapsUwpjFJg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

如图，使用高水位来区分消息是否已提交，消费者只能读取已提交的数据。

水位的更新取决于 leader 副本与 follow 副本之间水位的**低值**。

比如leader 分区的高水位:(LEO-n为各个副本的当前同步的offset值)

currentHW = max{currentHW, min（LEO-1, LEO-2, ……，LEO-n）}。

因此，当有多个分区且分区同步速度有一定延迟时，也会影响consumer的可读取范围。

当然这都是在消费速度跟得上的情况下，kafka队列的延迟基本都在毫秒级[5]，相比于消费者异常或者消费速度低下,导致消息积压带来的延迟，基本可以忽略不计了。

**实时性Vs 写入量**

对于一些内容推荐的场景来讲，秒级的更新基本够用了，对于有些业务场景，即使整体序列更新增加个5秒，可能对线上效果影响也不太大。(模型和样本更新远达不到这个速度，但也需要上线做对比实验~)

适当的降低实时性，能够极大减少对线上kv的写入量，特别是对于曝光序列来说，举个例子,下面的是B站的推荐列表:

![图片](https://mmbiz.qpic.cn/mmbiz_png/JwPJIDC9UgKxQj4OOLaleJZT6erXltux7MHJ78jqwlXezXqmaY9RrI2mDbGeugOyiarwiaiaW1vibqvpD6bt8IoT0g/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

每次下拉刷新会展示6-10条，一屏能展示8条。也就是一次请求可能会同时上报8条曝光行为，假如每上报一条更新一次kv，就需要读写kv一共16次。

但这些曝光基本都是同时发生的，假如在消费事件时，按照用户id做简单的窗口等待个n秒钟，把8个曝光行为收拢为1个List,更新kv的时候也就只需要1次读和1次写，对于kv压力也会极大的减小。

实际序列等待窗口时间长短，也是根据业务实时性的要求和工程复杂度的整体考量，可以写个程序，统计下不同时间窗口对于数据读写量的聚合率，取一个性价比高的数值。

### 2.2 写冲突与顺序性

在更新用户序列时,一般是append操作。先读取redis里面的值，再把新的行为加进去，然后再更新回redis。

kafka每个分区对应一个序列计算线程，因此可能会出现单个用户同时更新redis的并发写问题。

比如下图:用户有a1,a2,a3三个行为，虽然redis本身是单线程的，但是假如同时来了3个 get & set 操作，可能会出现值覆盖，造成最终结果错误。

![图片](https://mmbiz.qpic.cn/mmbiz_png/JwPJIDC9UgKxQj4OOLaleJZT6erXltuxA4fYWGJzow9AFDp6dfkMT5GWzOkib4VkMNplZnrt65CZ2D6EsYXvnDw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

常见的方案是将并发改为串行化，如下图。

由于kafka只能保证单分区有序，因此上报时可以根据uid partitionBy 指定发送到对应分区。

当然也可以在kafka消费端做，比如写入作业是flink的话，可以使用 keyBy(uid)算子，将相同用户的序列shuffle到同个算子里，相应的读写redis的操作也变成串行化，没有并发更新问题。

正常情况下埋点上报不会刻意使用partitionby分区上报，因此在消费端做下shuffle即可。

![图片](https://mmbiz.qpic.cn/mmbiz_png/JwPJIDC9UgKxQj4OOLaleJZT6erXltuxe0HvL72Vfl9rEiaZSdiaRt0gQ7PLFymWbblN6I0vu0FBGRldjE7FZcGQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

flink消费端做keyby shuffle不仅可以避免并发写，还可以一定程度解决kafka的乱序问题。

kafka每个topic拥有多个分区，通过扩大分区来进行横向扩容。每个分区leader可能分布在不同的机器上，有时候会因为一些网络抖动或者磁盘问题，会导致个别分区消费速度慢或者不稳定，因此先写入的数据，可能较后消费到，导致写入乱序。

Flink 在keyby 的时候，可以按照每个用户等待一定的时间窗口，窗口触发时对事件按照时间戳排序，然后再将list更新回redis(单事件的话可以从后向前插入)。

当然也可以直接使用flink 的event time机制，但处理起来稍微麻烦些，因为迟到的数据也同样需要有序的更新回redis中。

### 2.3 一致性

简单来讲，序列行为特征生产写入过程中，不能多，也不能缺胳膊少个腿。整个序列特征的生产写入跨了 kafka + flink + redis，多个系统，如何确保分布式系统，数据从源头到终点都保证准确性，是个不小的难点。

在消息处理引擎中一般提供三种语义:

**最多一次（At-most-once）**：用户的数据只会被处理一次，不管成功还是失败，不会重试也不会重发 

**至少一次（At-least-once）**：系统保证数据或事件至少被处理一次。如果中间发生错误或者丢失，那么会从源头重新发生一条然后进入处理系统，所以同一个时间或者消息会被处理多次

 **精确一次（Exactly-once）**：表示每一条数据只会被精确地处理一次，不多也不少

kafka自身通过刷盘机制+ISR副本等机制来保证消息不丢失，同时 pid和sequnce number等也保证了生产端的重复性(更多细节等后面抽空了来统一整理下)。

flink也是，作业异常，**可以通过checkpoint机制恢复之前的状态保证数据不会丢失**，但由于下游存储是redis，跨系统了，有可能更新到一半，但是flink挂了，重启恢复的时候，又会再次更新一遍redis的内容。导致数据重复。

分布式系统端到端的exactly once解决方案，大体分为两种:

1. 事务:
2. 幂等性:

在flink 系统中，端到端的事务需要下游存储支持，同时性能和延迟也会略打折扣，比如kafka在长事务下就会较大影响性能。

在序列特征生产场景下，可以通过幂等性来规避特征的重复写，最常见的幂等性的实现是通过**时间戳或者版本号机制**

![图片](https://mmbiz.qpic.cn/mmbiz_png/JwPJIDC9UgKxQj4OOLaleJZT6erXltuxQaeXmGD2RwtpUEl7ZiaQ0TU5ribW2NKsP2H5y1Cz1yo1sFtYCnpOjicsg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

即redis中保存更新的时间戳，**flink 程序每次update的时候，对比下redis与本地事件的事件戳，假如小于则本次不更新**。

这种机制相对简单，也可以避免大开销的事务。

## 3. 存储结构

前面章节介绍了序列特征生产过程中可能的实时性+并发写+一致性的问题，那具体到存储结构上，如何设计，或者设计上应该考虑哪些点？

从个人过往的工作经验出发，我主要列了以下几个考量点:

1. 存储大小:不同数据结构对于存储成本
2. 性能: 序列化开销，不同长度对序列化的影响。
3. 扩展性: 字段扩展，和业务需求变更的扩展，是否也能够灵活支持。

从上面几个角度，我简单列举了 redis list 结构与 redis protobuf value 结构的一些对比。

![图片](https://mmbiz.qpic.cn/mmbiz_png/JwPJIDC9UgKxQj4OOLaleJZT6erXltuxVuypoBBDwQgmsDafCT4yViaT0DEfOcTlYW1MoJu5GmMx5nN4cOicicVIg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)



| 对比项 | redis list 结构                                              | redis protobu 结构                                           |
| ------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 优点   | 1. 更新时直接push数据，无需先读后写 2.无并发更新问题 3. 可以lrange 按需取n条序列 | 1. 可以进行整体压缩， 2. 可以存储符合结构，比如更多的side info,方便扩展 3. 可以针对item进行去重。 |
| 缺点   | 1. list 存储每个itemid，无法进行去重。 2. 无法进行压缩，序列较长时，存储较大 3. 每个list存储itemid，较难存储更多item 信息。 | 1. 每次更新时需要先读后写(client 读取后decode,update 完后encode回pb) 2. 需要关注并发写问题 |

从去重 + 存储大小(可压缩) + 存储复合嵌套结构方便扩展的角度，**一般都会偏向于使用protobuf结构**。

针对side info 问题，比如pb 中是否存储更多item 相关的信息，比如分类信息，作者或者详情等等,大部分情况下倾向于不存。

不仅仅是因为每个item的side info可能很大，**用户假如有200个行为的话，整个pb结构会偏大，占用存储同时更加剧了大key的风险，而且有些分类信息也可能会变化过期等等**。

## 4 总结

本文只是简单列举了序列特征服务工程实践中的常见问题，**不同的业务对于序列特征服务要求不尽相同**，比如电商或者广告场景，序列特征还要提供跨session的计算。针对side info 也有很多常见的特征计算需求，比如基于序列特征，统计最近3,7,12/小时/天 观看最多的商品分类，内容分类，tag分类，或者主播类型等等。







































