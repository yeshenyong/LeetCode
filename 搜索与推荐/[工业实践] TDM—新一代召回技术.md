# TDM——新一代召回技术



参考

https://zhuanlan.zhihu.com/p/78488485

https://zhuanlan.zhihu.com/p/93201318

https://baijiahao.baidu.com/s?id=1719260858422163440





### 背景

随着整个互联网行业的发展，各大互联网公司作为服务提供商，积累了越来越多能够服务用户的优质内容，如电商领域的各类商品、视频领域丰富的视频、直播等。而随着信息量的爆炸，算法技术作为连接内容和用户的桥梁，在服务质量的提升上发挥着至关重要的作用。随着业界在搜索、推荐、广告技术上多年的迭代积累，逐步形成了较为稳定的召回（匹配）、粗排、精排这一多阶段的系统架构，而召回模块及其相关的算法，在各类业务中处于链路最前端，其决定着整体服务质量的天花板





### 简单的一段式检索向量召回的缺点

在推荐和相关领域，简单的一段式全库检索的经典代表，其实借鉴了图像检索的算法，即：内积模型的向量检索。它通过各种方式学到了 Item 的 Embedding，然后通过 PQ 方式构建分库索引，检索时实时计算 User Embedding，做最近邻 TopK Item 检索。内积模型向量检索在 Facebook 17年开源了 FAISS 库后，得到了广泛的应用。这种一段式全库检索，在发现能力上具有一定优势，但缺点是模型比较简单，能力有限。这里以 PCTR 预估为例，内积模式的 DQM、Attention 的 DIN、Attention+GRU 的 DIEN 做比较来看，内积模式的 AUC 是最低的，间接证明了内积模型是存在能力局限的

![img](https://pic.rmb.bdstatic.com/bjh/news/64066513b847c1e860a74ae133d737a7.png)







![img](https://pic4.zhimg.com/v2-c7a1714f03e5a0f2dbd94d78db1e54f7_r.jpg)

### TDM 模型

（Tree-based Deep Match）

**检索技术=模型能力+索引效能**

#### Beam Search

以十亿商品为例我们可以构建一棵30层的树，检索 Top1 我们只需要计算30次

1、文中指出绿色框中树形结构的叶子节点表征的是具体的每一个商品，具有明确的物理意义（如叶子节点8代表粗跟高跟鞋，叶子节点9代表细跟高跟鞋），而非叶子节点则是对商品的进一步抽象化表征，是一种更粗粒度的表征（如节点4可能代表的是高跟鞋，当然节点4可能也不具备明确的屋里意义），总之父节点相较于子节点来说是一种更粗粒度的表征。

2、在这种树形索引结构的基础上如何保证检索的高效性呢，文中指出为高效的检索出Top-K的商品，该树形结构实际上是一种类似于最大堆的树结构，并且对于用户u来说，对l层非叶子节点n的偏好概率表征如下式：

![img](https://pic1.zhimg.com/v2-8ebbfb6037db2cedc564ee499b378548_r.jpg)用户-商品偏好概率（兴趣建模）

其中p(n|u)表示的就是用户u对j层节点n感兴趣的概率，α(j)是归一化因子，从上式可以得出，用户u对j层节点n感兴趣的概率，等于用户对该节点的子节点的偏好概率的最大值（上述过程就是文中所述的兴趣建模）。所以我们如果最终需要检索出Top-K个商品，只需要自顶向下的在每一层检索出当前层的Top-K节点，但是当前层的检索集是上一层Top-K节点的子节点，从这些子节点中检索出当前层的Top-K节点。具体举例来说，如图中绿色框的树形结构，最终要检索Top-2商品，那么从树的第二层开始，a）我们选取第二层的Top-K节点(2和3)；b)在第三层的时候，根据上述公式，我们可以知道该层的Top-2的一定位于节点2和节点3的子节点中，所以我们只需要从4、5、6、7节点中检索Top-2，假设检索结果是节点5和6；c)在第四层中我们检索该层的Top-2，根据公式可以知道该层的Top-2节点一定存在于节点5和6的叶子节点中，所以只需要从叶子节点10、11、12、13中检索出最终的Top-2节点，上述检索过程即为Beam Search方式

3、在了解TDM是如何实现检索过程之后，还需要解决的问题就是如何对每层选取Top-K节点，具体做法就如上图中的红色框的部分，该部分的输入包括用户的历史行为特征以及节点的Embedding特征，在对每一层选取Top-K的时候，需要将这一层的每一个节点输入左侧模型中得到相应的预测分数，最终根据分数来取Top，文中指出TDM可以任意复杂的排序模型也得益于这种系统架构。当然构建模型训练所需的训练样本的过程中涉及到对负样本的采样操作，具体可以参考论文中的表述

4、利用采样得到训练样本之后，相应的损失函数如下所示：

![img](https://pic2.zhimg.com/v2-602d42670ed659caae66697d7f64f9ed_r.jpg)损失函数

在给定训练样本和损失函数的基础上，接下来需要做的就是进行模型的训练，整个系统包括树形索引结构和深层排序结构两部分，文中采用的是联合训练的方式，整体联合训练的方式如下：a)初始化一棵树然后基于该树训练深层模型直到其收敛；b)基于训练好的深层模型（包括叶子节点的embedding部分），利用节点的Embedding重新构建一颗新的树；c)基于新的树结构，重新训练深层模型。

具体的，在初始化树结构的时候，首先借助商品的类别信息进行排序，将相同类别的商品放到一起，然后递归的将同类别中的商品等量的分到两个子类中，直到集合中只包含一项，利用这种自顶向下的方式来初始化一棵树。基于该树采样生成深度模型训练所需的样本，然后进一步训练模型，训练结束之后可以得到每个树节点对应的Embedding向量，利用节点的Embedding向量，采用K-Means聚类方法来重新构建一颗树，最后基于这颗新生成的树，重新训练深层网络。

#### 



### 总结

![img](https://pic3.zhimg.com/80/v2-f06de0eba171367c5824cf291f73a40a_720w.jpg)



总结一下 TDM 提出、设计和实现的脉络：

- 目标：解决从超大规模全量商品库中高效检索 TopK 商品的问题
- 思考：希望由先进模型带来性能/效果的提升；为赋能先进模型，需要高效索引；由此产生最大堆树的理论建模
- 探索：基于最大堆树，我们链接了 BeamSearch 检索下深度学习模型和高效树索引联合学习的方式，形成了基于学习树的全库索引的检索框架





**▌深度树检索技术对于线上业务场景的适配应用**



![img](https://pic2.zhimg.com/80/v2-e593887197c510c2ec570d50144bd835_720w.jpg)



原生 TDM 是兴趣最优的检索方案，但是在实际业务中，有些业务目标不一定是兴趣最优。例如在广告业务中，我们要考虑 ECPM 最优。那么，我们要如何改造 TDM，[使得其可以满足不同的业务目标？](https://zhuanlan.zhihu.com/p/78488485)

