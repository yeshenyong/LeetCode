# 离线度量评价指标

### ROC-AUC

roc曲线上每个点反映着对同一信号刺激的感受性



#### ROC 曲线的动机

​	对于0,1两类分类问题,一些分类器得到的结果往往不是0,1这样的标签,如神经网络,得到诸如0.5,0,8这样的分类结果。这时,我们人为取一个阈值,比如0.4,那么小于0.4的为0类,大于等于0.4的为1类,可以得到一个分类结果。同样,这个阈值我们可以取0.1,0.2等等。取不同的阈值,得到的最后的分类情况也就不同。 
如下面这幅图: 

![这里写图片描述](https://img-blog.csdn.net/20171121193700211)

​	蓝色表示原始为负类分类得到的统计图,红色为正类得到的统计图。那么我们取一条直线,直线左边分为负类,右边分为正,这条直线也就是我们所取的阈值。 
​	阈值不同,可以得到不同的结果,但是由分类器决定的统计图始终是不变的。这时候就需要一个独立于阈值,只与分类器有关的评价指标,来衡量特定分类器的好坏。 
​	**还有在类不平衡的情况下,如正样本90个,负样本10个,直接把所有样本分类为正样本,得到识别率为90%。但这显然是没有意义的。** 
如上就是ROC曲线的动机。 

ROC空间将假正例率（False Positive Rate, 简称FPR）定义为 X轴，真正例率（True Positive Rate, 简称TPR）定义为 Y 轴。这两个值由上面四个值计算得到,公式如下: 

**TPR：**在所有实际为正例的样本中，被正确地判断为正例之比率。 

![img](https://img-blog.csdn.net/20180729001310849?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjE4MDgxMA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

**FPR：**在所有实际为反例的样本中，被错误地判断为正例之比率。 

![img](https://img-blog.csdn.net/20180729001332635?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjE4MDgxMA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

我们以FPR为横轴,TPR为纵轴,得到如下ROC空间。 

![这里写图片描述](https://img-blog.csdn.net/20171121195654765)

我们可以看出,左上角的点(TPR=1,FPR=0)(TPR=1,FPR=0),为完美分类。曲线距离左上角越近,证明分类器效果越好。点A(TPR>FPR)表明判断大体是正确的。中线上的点B(TPR=FPR)表明判定一半对一半错（这种最垃圾~~）;下半平面的点C(TPR<FPR)说明判定大体错误。

![这里写图片描述](https://img-blog.csdn.net/20171121201138792)



如上,是三条ROC曲线,在0.23处取一条直线。那么,在同样的低FPR=0.23的情况下,红色分类器得到更高的PTR。也就表明,ROC越往上,分类器效果越好。我们用一个标量值AUC来量化它。



auc其实就是ROC曲线围成的面积！！
在两个分类器的ROC曲线交叉的情况下，无法判断哪个分类器性能更好，这时可以计算ROC曲线下面积AUC，作为性能度量，面积越大则越好。 



#### 为什么使用ROC-AUC 

既然已经这么多标准，为什么还要使用ROC和AUC呢？因为ROC曲线有个很好的特性：当测试集中的正负样本的分布变换的时候，ROC曲线能够保持不变。在实际的数据集中经常会出现样本类不平衡，即正负样本比例差距较大，而且测试数据中的正负样本也可能随着时间变化。下图是ROC曲线和Presision-Recall（P-R）曲线的对比： 

![这里写图片描述](https://img-blog.csdn.net/20171122094409104)

在上图中，(a)和(c)为Roc曲线，(b)和(d)为P-R曲线。

(a)和(b)展示的是分类其在原始测试集**(正负样本分布平衡**)的结果，(c)(d)是将测试集中**负样本的数量增加到原来的10倍后**，分类器的结果，可以明显的看出，**ROC曲线基本保持原貌，而Precision-Recall曲线变化较大。**



### RP-AUC

PR 曲线

以precision 作为纵轴，recall 作为横轴，在坐标轴上绘制出这些P-R 数组，在连成曲线，即可得到相应的P-R 曲线图。

![img](https://img-blog.csdn.net/20180729001105702?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjE4MDgxMA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

从图上所示，不同的算法，对应着不同的P-R曲线。如图所示，我们有A，B，C三条曲线。通常，我们认为如果一条曲线甲，能够被另一条曲线乙包住，则认为乙的性能优于甲。在上图所示，就是曲线B的性能要高于曲线C。但是A和B发生了交叉，所以不能判断出A、B之间哪个算法更优。 比较两个分类器好坏时，显然是查得又准又全的比较好，也就是的PR曲线越往坐标（1，1）的位置靠近越好。因此，在图上标记了“平衡点（Break-Even Point，简称BEP）”。它是“P-R”时的取值，同时也是我们衡量算法优劣的一个参考。





### F1-score

![这里写图片描述](https://img-blog.csdn.net/20171121170409420)

accuracy rate（准确率）

![img](https://img-blog.csdn.net/20180729000805991?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjE4MDgxMA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

precision（精准率）

![img](https://img-blog.csdn.net/20180729000428394?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjE4MDgxMA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

recall（召回率）

![img](https://img-blog.csdn.net/20180729000511777?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjE4MDgxMA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

调和平均数 F1-score

![img](https://img-blog.csdn.net/20180729002853876?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjE4MDgxMA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

### hit recall Rate

召回命中率（较为简单）































