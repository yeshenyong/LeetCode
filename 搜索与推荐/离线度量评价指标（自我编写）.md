# 离线度量评价指标

### ROC-AUC

roc曲线上每个点反映着对同一信号刺激的感受性



#### ROC 曲线的动机

​	对于0,1两类分类问题,一些分类器得到的结果往往不是0,1这样的标签,如神经网络,得到诸如0.5,0,8这样的分类结果。这时,我们人为取一个阈值,比如0.4,那么小于0.4的为0类,大于等于0.4的为1类,可以得到一个分类结果。同样,这个阈值我们可以取0.1,0.2等等。取不同的阈值,得到的最后的分类情况也就不同。 
如下面这幅图: 

![这里写图片描述](https://img-blog.csdn.net/20171121193700211)

​	蓝色表示原始为负类分类得到的统计图,红色为正类得到的统计图。那么我们取一条直线,直线左边分为负类,右边分为正,这条直线也就是我们所取的阈值。 
​	阈值不同,可以得到不同的结果,但是由分类器决定的统计图始终是不变的。这时候就需要一个独立于阈值,只与分类器有关的评价指标,来衡量特定分类器的好坏。 
​	**还有在类不平衡的情况下,如正样本90个,负样本10个,直接把所有样本分类为正样本,得到识别率为90%。但这显然是没有意义的。** 
如上就是ROC曲线的动机。 

ROC空间将假正例率（False Positive Rate, 简称FPR）定义为 X轴，真正例率（True Positive Rate, 简称TPR）定义为 Y 轴。这两个值由上面四个值计算得到,公式如下: 

**TPR：**在所有实际为正例的样本中，被正确地判断为正例之比率。 

![img](https://img-blog.csdn.net/20180729001310849?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjE4MDgxMA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

**FPR：**在所有实际为反例的样本中，被错误地判断为正例之比率。 

![img](https://img-blog.csdn.net/20180729001332635?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjE4MDgxMA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

我们以FPR为横轴,TPR为纵轴,得到如下ROC空间。 

![这里写图片描述](https://img-blog.csdn.net/20171121195654765)

我们可以看出,左上角的点(TPR=1,FPR=0)(TPR=1,FPR=0),为完美分类。曲线距离左上角越近,证明分类器效果越好。点A(TPR>FPR)表明判断大体是正确的。中线上的点B(TPR=FPR)表明判定一半对一半错（这种最垃圾~~）;下半平面的点C(TPR<FPR)说明判定大体错误。

![这里写图片描述](https://img-blog.csdn.net/20171121201138792)



如上,是三条ROC曲线,在0.23处取一条直线。那么,在同样的低FPR=0.23的情况下,红色分类器得到更高的PTR。也就表明,ROC越往上,分类器效果越好。我们用一个标量值AUC来量化它。



auc其实就是ROC曲线围成的面积！！
在两个分类器的ROC曲线交叉的情况下，无法判断哪个分类器性能更好，这时可以计算ROC曲线下面积AUC，作为性能度量，面积越大则越好。 



#### 为什么使用ROC-AUC 

既然已经这么多标准，为什么还要使用ROC和AUC呢？因为ROC曲线有个很好的特性：当测试集中的正负样本的分布变换的时候，ROC曲线能够保持不变。在实际的数据集中经常会出现样本类不平衡，即正负样本比例差距较大，而且测试数据中的正负样本也可能随着时间变化。下图是ROC曲线和Presision-Recall（P-R）曲线的对比： 

![这里写图片描述](https://img-blog.csdn.net/20171122094409104)

在上图中，(a)和(c)为Roc曲线，(b)和(d)为P-R曲线。

(a)和(b)展示的是分类其在原始测试集**(正负样本分布平衡**)的结果，(c)(d)是将测试集中**负样本的数量增加到原来的10倍后**，分类器的结果，可以明显的看出，**ROC曲线基本保持原貌，而Precision-Recall曲线变化较大。**



### RP-AUC

PR 曲线

以precision 作为纵轴，recall 作为横轴，在坐标轴上绘制出这些P-R 数组，在连成曲线，即可得到相应的P-R 曲线图。

![img](https://img-blog.csdn.net/20180729001105702?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjE4MDgxMA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

从图上所示，不同的算法，对应着不同的P-R曲线。如图所示，我们有A，B，C三条曲线。通常，我们认为如果一条曲线甲，能够被另一条曲线乙包住，则认为乙的性能优于甲。在上图所示，就是曲线B的性能要高于曲线C。但是A和B发生了交叉，所以不能判断出A、B之间哪个算法更优。 比较两个分类器好坏时，显然是查得又准又全的比较好，也就是的PR曲线越往坐标（1，1）的位置靠近越好。因此，在图上标记了“平衡点（Break-Even Point，简称BEP）”。它是“P-R”时的取值，同时也是我们衡量算法优劣的一个参考。





### F1-score

![这里写图片描述](https://img-blog.csdn.net/20171121170409420)

accuracy rate（准确率）

![img](https://img-blog.csdn.net/20180729000805991?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjE4MDgxMA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

precision（精准率）

![img](https://img-blog.csdn.net/20180729000428394?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjE4MDgxMA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

recall（召回率）

![img](https://img-blog.csdn.net/20180729000511777?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjE4MDgxMA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

调和平均数 F1-score

![img](https://img-blog.csdn.net/20180729002853876?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjE4MDgxMA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

### hit recall Rate

召回命中率（较为简单）



### NDCG

NDCG，Normalized Discounted cumulative gain 直接翻译为归一化折损累计增益，可能有些晦涩，没关系下面重点来解释一下这个评价指标。这个指标通常是用来衡量和评价搜索结果算法（注意这里维基百科中提到了还有推荐算法，但是我个人觉得不太适合推荐算法，后面我会给我出我的解释）。DCG的两个思想：

　　1、高关联度的结果比一般关联度的结果更影响最终的指标得分；

　　2、有高关联度的结果出现在更靠前的位置的时候，指标会越高；

 

**累计增益（CG）**

　　CG，cumulative gain，是DCG的前身，只考虑到了相关性的关联程度，没有考虑到位置的因素。它是一个搜素结果相关性分数的总和。指定位置p上的CG为：

![img](https://images2018.cnblogs.com/blog/626346/201808/626346-20180801211637208-105177566.png)

　　reli 代表i这个位置上的相关度。

　　举例：假设搜索“篮球”结果，最理想的结果是：B1、B2、 B3。而出现的结果是 B3、B1、B2的话，CG的值是没有变化的，因此需要下面的DCG。

 

**折损累计增益（DCG）**

　　DCG， Discounted 的CG，就是在每一个CG的结果上处以一个折损值，为什么要这么做呢？目的就是为了让排名越靠前的结果越能影响最后的结果。假设排序越往后，价值越低。到第i个位置的时候，它的价值是 1/log2(i+1)，那么第i个结果产生的效益就是 reli * 1/log2(i+1)，所以：

![img](https://images2018.cnblogs.com/blog/626346/201808/626346-20180802095305134-407900823.png)

　　当然还有一种比较常用的公式，用来增加相关度影响比重的DCG计算方式是：

![img](https://images2018.cnblogs.com/blog/626346/201808/626346-20180802095414809-1103241697.png)

　　百科中写到后一种更多用于工业。当然相关性值为二进制时，即 reli在{0,1}，二者结果是一样的。当然CG相关性不止是两个，可以是实数的形式。

 

**归一化折损累计增益（NDCG）**

　　NDCG， Normalized 的DCG，由于搜索结果随着检索词的不同，返回的数量是不一致的，而DCG是一个累加的值，没法针对两个不同的搜索结果进行比较，因此需要归一化处理，这里是处以IDCG。

![img](https://images2018.cnblogs.com/blog/626346/201808/626346-20180802095442260-1482932356.png)

　　IDCG为理想情况下最大的DCG值。

![img](https://images2018.cnblogs.com/blog/626346/201808/626346-20180802095515537-806452955.png)

　　其中 |REL| 表示，结果按照相关性从大到小的顺序排序，取前p个结果组成的集合。也就是按照最优的方式对结果进行排序。

 

 **实际的例子**

　　假设搜索回来的5个结果，其相关性分数分别是 3、2、3、0、1、2

　　那么 CG = 3+2+3+0+1+2

　　可以看到只是对相关的分数进行了一个关联的打分，并没有召回的所在位置对排序结果评分对影响。而我们看DCG：

| i    | reli | log2(i+1) | reli /log2(i+1) |
| ---- | ---- | --------- | --------------- |
| 1    | 3    | 1         | 3               |
| 2    | 2    | 1.58      | 1.26            |
| 3    | 3    | 2         | 1.5             |
| 4    | 0    | 2.32      | 0               |
| 5    | 1    | 2.58      | 0.38            |
| 6    | 2    | 2.8       | 0.71            |

　　所以 DCG = 3+1.26+1.5+0+0.38+0.71 = 6.86

　　接下来我们归一化，归一化需要先结算 IDCG，假如我们实际召回了8个物品，除了上面的6个，还有两个结果，假设第7个相关性为3，第8个相关性为0。那么在理想情况下的相关性分数排序应该是：3、3、3、2、2、1、0、0。计算IDCG@6:

| i    | reli | log2(i+1) | reli /log2(i+1) |
| ---- | ---- | --------- | --------------- |
| 1    | 3    | 1         | 3               |
| 2    | 3    | 1.58      | 1.89            |
| 3    | 3    | 2         | 1.5             |
| 4    | 2    | 2.32      | 0.86            |
| 5    | 2    | 2.58      | 0.77            |
| 6    | 1    | 2.8       | 0.35            |

　　所以IDCG = 3+1.89+1.5+0.86+0.77+0.35 = 8.37

　　so 最终 NDCG@6 = 6.86/8.37 = 81.96%



### MAE

1、平均绝对误差（Mean Absolute Error, MAE）：是绝对误差的平均值，可以更好地反映预测值误差的实际情况

```python
def MAE(Y_real,Y_pre):#计算MAE
    from sklearn.metrics import mean_absolute_error
    return mean_absolute_error(Y_real,Y_pre)#Y_real为实际值，Y_pre为预测值
```

### RMSE MSE

均方误差（Mean Square Error, MSE）：是真实值与预测值的差值的平方，然后求和的平均，一般用来检测模型的预测值和真实值之间的偏差

```python
def MSE(Y_real,Y_pre):#计算MSE
    from sklearn.metrics import mean_squared_error
    return mean_squared_error(Y_real,Y_pre)#Y_real为实际值，Y_pre为预测值
```

均方根误差（Root Mean Square Error, RMSE）：即均方误差开根号，方均根偏移代表预测的值和观察到的值之差的样本标准差

```python
def RMSE(Y_real,Y_pre):#计算RMSE
    from sklearn.metrics import mean_squared_error
    return np.sqrt(mean_squared_error(Y_real,Y_pre))#Y_real为实际值，Y_pre为预测值
```

























