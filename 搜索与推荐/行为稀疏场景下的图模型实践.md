# 行为稀疏场景下的图模型实践



### 背景

在视频推荐系统中，有相当一部分用户的行为较为稀疏，基于行为序列建模的方式无法较好的对这部分用户的兴趣进行表征.  针对场景行为稀疏的问题，学术和业内有多种解决方案。最直观的方案是深度发掘side info的威力，在用户和内容缺乏行为关联的情况下，通过side info构建更多的关联，这一块的内容我们在基于content-base召回有一些实践，感兴趣的同学可以移步[https://mp.weixin.qq.com/s/Ari-xyJPkla-h5IsQAeiJQ](https://mp.weixin.qq.com/s?__biz=MzAxNDEwNjk5OQ==&mid=2650445349&idx=1&sn=bb8ad24cef7f34bd46fe35d0cb370958&scene=21#wechat_redirect)；第二种是通过预训练的方法，通过行为稠密用户训练得到表达较为充分的公共模型，然后在行为稀疏用户上进行fineturn；第三种可以利用跨域行为，在源域行为稀疏的情况下，利用其它域内的行为构建联系，但是这个存在的问题就是其它域内学习到的兴趣并不一定能真正代表用户在源域内的兴趣；第四种是利用知识图谱构建图模型，通过Meta-learning的范式学习出用户表达；其他的也有通过构建u2u的同构图，通过相似行为稠密用户去表达行为稀疏用户，但是这种方式依赖于u2u的图谱构建。



本文拟从图模型的角度出发，探索解决用户稀疏行为的图模型方法。事实上，图模型在推荐系统中应用的越来越广泛，但是传统的图模型在构图的时候依赖用户的行为，我们尝试在构图的时候加入内容图谱的信息，通过内容图谱构建用户行为图。图模型在实际推荐系统中的应用主要是两类方法：**path-based和embedding-based.**



其中，embedding-based model就是将图网络先预训练成embedding，然后将embedding输入到模型中，比如KGE，CKE，DKN，SHINE等都是这种方式，这种方式的好处是可以分开建模，但是缺点是预训练和推荐任务是分离的，在embedding的训练上没法做到面向任务训练，而且存在图结构更新的问题。另外一种就是path-based方法，主要是把图谱原始结构输入，比如RippleNet，Personalized Entity Recommendation (PER) 和 Meta-Graph Based Recommendation，KGAT等，这种方式是把整个图谱原始信息输入到模型中去，靠模型端到端的学习出对应表达。



针对用户行为稀疏的问题，我们提出了一种较为新颖的稀疏行为场景下序列扩展的方法，通过v2v+知识图谱的行为扩展方式，并结合多种信息聚合方式，我们迭代了多版模型，在行为稀疏用户上取得了pctr +6%的效果。



### 新颖的稀疏行为场景下图谱扩展图谱模型

和一般的图模型建模思路类似，我们提出的稀疏场景下行为序列扩展方法一共包含两个部分，第一步基于某种数据构建图的拓扑结构；第二步在图中进行某种信息聚合。其中，拓扑结构的建立我们结合了u2v2v和基于图谱的图模型，其中u2v2v虽然只是user->video->video的扩展，但是实际还是u2u的扩展关系。因为其中的video->video的关系是通过整个训练集合中video->user->video的关系构建得到。如图所示，用户小明的行为中的视频序列，会同时有多个行为较为稠密的用户也同时感兴趣，而这部分用户的兴趣我们可以通过他们点击/观看的视频表示，这样子就可以通过u->v->u->v的扩展方式将行为稠密的用户感兴趣的视频去表达用户小明，而其中小明行为->稠密用户->稠密用户感兴趣视频的二部图则可以用swing v2v来表达。

![图片](https://mmbiz.qpic.cn/mmbiz_png/33P2FdAnjuibZIicbtDOnBfb6zQTnRoOkYT54v6yUE1NfYVyfKNRXYnFAK3y8NGHxlZ8tOJHmBcffX4ZEGpGsVKA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

这样通过v2v的方式，间接的实现将行为稠密的用户的表达(video set)去表征行为稀疏的用户。考虑到这种扩展的关系不是完备的，所以还会用基于认知图谱的图模型扩展的结果进行辅助扩充，保证扩展关系的完备性。通过v2v和图谱的扩展之后，对于行为稀疏的用户我们可以将拓扑结构由序列变为图谱，如下图所示。

![图片](https://mmbiz.qpic.cn/mmbiz_png/33P2FdAnjuibZIicbtDOnBfb6zQTnRoOkYsiaXjKyqMHBKHB4DtVYFyEjuCzsn6iaFbm7rqEQ5OjIW6wxqaWX2WTKQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

在得到图谱结构之后，如何表征用户行为便是下一步需要解决的问题了。在传统的序列+transformer的架构中，序列embedding之后经过self-attention便得到序列的初始表达。序列拓扑结构改变之后，信息聚合的方式也相应会发生变化。从以往的序列attention的范式变为按照图拓扑结构进行聚合了。一般可以通过某种聚合函数对one-hop或者multi-hops节点的信息进行聚合。一般的聚合方式包括：

1. GCN聚合

   ![图片](https://mmbiz.qpic.cn/mmbiz_png/33P2FdAnjuibZIicbtDOnBfb6zQTnRoOkYP4n2Y4Nn3mtkykVJ2Rsz0yeEhRGcUl1gp0KV6uibV5mhE7hibzpCqZ3w/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

2. GraphSage聚合

   ![图片](https://mmbiz.qpic.cn/mmbiz_png/33P2FdAnjuibZIicbtDOnBfb6zQTnRoOkYYnULx6D5usaHfiahiaQvRBhiaG6j8O8FNDmribIwYI5BEz3dqfEHaXZjuA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

3. Bi-Interaction Aggregator

   ![图片](https://mmbiz.qpic.cn/mmbiz_png/33P2FdAnjuibZIicbtDOnBfb6zQTnRoOkYd7GoW5oG4icThQ3vs5U8OUBrJxa1obrD3sPXFzwmQicOzavV1K971sfQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)



我们先后迭代了基于rippleNet、基于GAT、图谱序列生成、KG-gating的方式，下面分别介绍。

### **基于图注意力的深度召回模型(GADM)**

在构建完基础的网络拓扑的基础之上，我们设计了多种信息聚合的方式，最开始的版本参考了rippleNet的attention，rippleNet是以用户感兴趣（点击/购买)的item作为初始锚点，然后在图谱中进行信息传递，对于H-hop的rippleNet每次ripple包含两个部分：



1. 通过用户初始锚点，构建初始的ripple set (h,r,t), 其中h可以表示为初始的兴趣锚点，r是兴趣锚点到扩展节点的relation, t则表示扩展节点。

2. 在原始的论文中，第二步是计算target item v和每一个扩展节点(h,r)的attention, 然后利用attention对扩展节点t进行加权求和得到output. 但是我们使用的场景是召回模型，这里使用target item来进行attention不现实，所以我们使用的relation和head的attention对tail进行加权求和，得到head的ripple 表达。

   ![图片](https://mmbiz.qpic.cn/mmbiz_png/33P2FdAnjuibZIicbtDOnBfb6zQTnRoOkYCg02vic7SGg60pAGpjcD9vibr796ku7MyOnAACSbcbib2gjnkxicjpHb6Q/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)



接着，在第二个hop中，将1-hop的tail作为2-hop的head, 1-hop得到的表达作为2-hop的head的表达（实际中在初始阶段为了上线rt, 我们只采用了1-hop)。



![图片](https://mmbiz.qpic.cn/mmbiz_png/33P2FdAnjuibZIicbtDOnBfb6zQTnRoOkY9fwVxvUMyRkm91d73p3DCWW88D1La0cdiaIm3fNEBgWBcPVDt5AxOww/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)



经过rippleNet的聚合之后，我们可以得到每一个感兴趣种子视频的表达，然后pooling成用户表达. 线上我们也没有扔掉原有序列表达，而是concat到一起作为用户序列表达。整个模型结构如下：



![图片](https://mmbiz.qpic.cn/mmbiz_png/33P2FdAnjuibZIicbtDOnBfb6zQTnRoOkYiaKzMiaAfrTXmMnovn1L2ux4HSMBEW9ugUXINcfI25arBYBelSdOF5bA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)



此外，考虑到聚合的时候的方式，依赖的是relation的表达，但是实际上relation所能表达的信息有限。所以我们进一步采用了类似于KGAT的聚合方式，通过参数自适应调节attention权重。



![图片](https://mmbiz.qpic.cn/mmbiz_png/33P2FdAnjuibZIicbtDOnBfb6zQTnRoOkY1nJx2HCXYaGqce7E97ibN233eMcfFdIcJXhkMxJaibMNk4UzUCDucEtw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)



模型上线之后，也取得了不错的效果.  其中 GADM-v1 pctr+1.5%, uctr +2.65%, GADM-v2 pctr +2.1%,uctr +1.4%。



下面待补充（感觉是复杂度提高的图模型，实现复杂度太高了，不符合召回模型复杂度的扩展）



















































